{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "filename_input = 'reviews_Automotive_5.json'\n",
    "# Load the raw data\n",
    "raw_data = [json.loads(line) for line in open(filename_input, 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate id_user_dict/id_item_dict/id_word_dict\n",
    "users = set()\n",
    "items = set()\n",
    "vocab = set()\n",
    "max_interaction_length = 0\n",
    "for line in raw_data:\n",
    "    UserID = line['reviewerID']\n",
    "    ItemID = line['asin']\n",
    "    sentence = re.sub(r'[^\\w\\s]|\\d','',line['reviewText'].lower())\n",
    "    words = [word for word in  sentence.split()]\n",
    "    if len(words) > max_interaction_length:\n",
    "        max_interaction_length = len(words)\n",
    "    users.add(UserID)\n",
    "    items.add(ItemID)\n",
    "    for word in words:\n",
    "        vocab.add(word)\n",
    "id_user_dict = dict(zip(range(len(users)), users))\n",
    "id_item_dict = dict(zip(range(len(items)), items))\n",
    "id_word_dict = dict(zip(range(len(vocab)), vocab))\n",
    "word_id_dict = dict(zip(vocab,range(len(vocab))))\n",
    "with open('id_user_dict', 'wb') as f:\n",
    "    pickle.dump(id_user_dict, f)\n",
    "with open('id_item_dict', 'wb') as f:\n",
    "    pickle.dump(id_item_dict, f)\n",
    "with open('id_word_dict', 'wb') as f:\n",
    "    pickle.dump(id_word_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of id_user_dict: 2928\n",
      "length of id_item_dict: 1835\n",
      "length of id_word_dict: 42430\n"
     ]
    }
   ],
   "source": [
    "print('length of id_user_dict:',len(id_user_dict))\n",
    "print('length of id_item_dict:',len(id_item_dict))\n",
    "print('length of id_word_dict:',len(id_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_by_value(value,D):\n",
    "    id = list(D.values()).index(value)\n",
    "    return list(D.keys())[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "item_reviews\n",
    "    Key: ItemID \n",
    "    Value: All the user reviews received by the Item\n",
    "user_item_review\n",
    "    Key: UserID@ItemID \n",
    "    Value: review from the user to the item\n",
    "user_purchased_items\n",
    "    Key: UserID\n",
    "    Value: list of purchasedID\n",
    "\"\"\"\n",
    "item_real_reviews = defaultdict(list)\n",
    "user_item_review = defaultdict(list)\n",
    "user_purchased_items = defaultdict(list)\n",
    "for line in raw_data:\n",
    "    # Turn the original ID into the index in the dictionary\n",
    "    UserID = get_key_by_value(line['reviewerID'], id_user_dict)\n",
    "    ItemID = get_key_by_value(line['asin'], id_item_dict)\n",
    "    item_real_reviews[ItemID].append(line)\n",
    "    UserItem = '{}@{}'.format(UserID,ItemID)\n",
    "    user_item_review[UserItem].append(line)\n",
    "    user_purchased_items[UserID].append(ItemID)\n",
    "with open('item_real_reviews', 'wb') as f:\n",
    "    pickle.dump(item_real_reviews, f)\n",
    "with open('user_item_review', 'wb') as f:\n",
    "    pickle.dump(user_item_review, f)\n",
    "with open('train_user_purchased_items', 'wb') as f:\n",
    "    pickle.dump(user_purchased_items, f)    \n",
    "with open('validation_user_purchased_items', 'wb') as f:\n",
    "    pickle.dump(user_purchased_items, f)        \n",
    "with open('test_user_purchased_items', 'wb') as f:\n",
    "    pickle.dump(user_purchased_items, f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/2928\n",
      "Processing 100/2928\n",
      "Processing 200/2928\n",
      "Processing 300/2928\n",
      "Processing 400/2928\n",
      "Processing 500/2928\n",
      "Processing 600/2928\n",
      "Processing 700/2928\n",
      "Processing 800/2928\n",
      "Processing 900/2928\n",
      "Processing 1000/2928\n",
      "Processing 1100/2928\n",
      "Processing 1200/2928\n",
      "Processing 1300/2928\n",
      "Processing 1400/2928\n",
      "Processing 1500/2928\n",
      "Processing 1600/2928\n",
      "Processing 1700/2928\n",
      "Processing 1800/2928\n",
      "Processing 1900/2928\n",
      "Processing 2000/2928\n",
      "Processing 2100/2928\n",
      "Processing 2200/2928\n",
      "Processing 2300/2928\n",
      "Processing 2400/2928\n",
      "Processing 2500/2928\n",
      "Processing 2600/2928\n",
      "Processing 2700/2928\n",
      "Processing 2800/2928\n",
      "Processing 2900/2928\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def parseStr(review):\n",
    "    ItemID = get_key_by_value(review['asin'], id_item_dict)\n",
    "    rating = review['overall']\n",
    "    time = review['unixReviewTime']\n",
    "    word_ids = []\n",
    "    review_text = re.sub(r'[^\\w\\s]|\\d','',review['reviewText'].lower())\n",
    "    for word in review_text.split():\n",
    "        word_id = word_id_dict[word]\n",
    "        word_ids.append(str(word_id)) \n",
    "    return '{}||{:1}||'.format(ItemID,rating)+'::'.join(word_ids)+\"||{}\".format(time)\n",
    "\n",
    "train = []\n",
    "validation = []\n",
    "test = []\n",
    "for UserID in range(len(id_user_dict)):\n",
    "    items = user_purchased_items[UserID]\n",
    "    if UserID % 100 == 0:\n",
    "        print('Processing {}/{}'.format(UserID,len(id_user_dict)))\n",
    "    reviews = []\n",
    "    for ItemID in items:\n",
    "        UserItem = '{}@{}'.format(UserID,ItemID)\n",
    "        reviews.append(user_item_review[UserItem][0])\n",
    "    reviews_sorted = sorted(reviews, key=lambda k: k['unixReviewTime']) \n",
    "    for i in range(2,len(reviews_sorted)):\n",
    "        target_review = reviews_sorted[i]\n",
    "        pre_review = reviews_sorted[i-1]\n",
    "        pre_pre_review = reviews_sorted[i-2]\n",
    "        row = '{}&&'.format(UserID)+parseStr(pre_review)+'()'+parseStr(pre_pre_review)+'&&'+parseStr(target_review)\n",
    "        if i < len(reviews_sorted) - 2:\n",
    "            train.append(row)\n",
    "        elif i == len(reviews_sorted) - 2:\n",
    "            test.append(row)\n",
    "        elif i == len(reviews_sorted) - 1:\n",
    "            validation.append(row)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output\n",
    "with open('train_ided_whole_data', 'w') as out_file:\n",
    "    out_file.write('\\n'.join(train))\n",
    "with open('validation_ided_whole_data', 'w') as out_file:\n",
    "    out_file.write('\\n'.join(validation))    \n",
    "with open('test_ided_whole_data', 'w') as out_file:\n",
    "    out_file.write('\\n'.join(test))\n",
    "with open('train_validation_ided_whole_data', 'w') as out_file:\n",
    "    out_file.write('\\n'.join(train+validation)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_statistics = {\n",
    "    'max_interaction_length': max_interaction_length,\n",
    "    'interaction_num': len(raw_data),\n",
    "    'max_sentence_length': 1,\n",
    "    'max_sentence_word_length': max_interaction_length,\n",
    "    'time_bin_number': 1,\n",
    "    'user_num': len(id_user_dict),\n",
    "    'item_num': len(id_item_dict),\n",
    "    'word_num': len(id_word_dict)\n",
    "}\n",
    "with open('data_statistics', 'wb') as f:\n",
    "    pickle.dump(data_statistics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
