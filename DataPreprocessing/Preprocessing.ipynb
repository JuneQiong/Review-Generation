{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necesarry packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = [json.loads(line) for line in open('Data/reviews_Musical_Instruments_5.json', 'r')]\n",
    "data = pd.read_json('Data/reviews_Musical_Instruments_5.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A2IBPI20UZIR0U</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A14VAT5EAX3D9S</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Jake</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>5</td>\n",
       "      <td>Jake</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>03 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A195EZSQDW3E21</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Rick Bennette \"Rick Bennette\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>The primary job of this device is to block the...</td>\n",
       "      <td>5</td>\n",
       "      <td>It Does The Job Well</td>\n",
       "      <td>1377648000</td>\n",
       "      <td>08 28, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A2C00NNG1ZQQG2</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>RustyBill \"Sunday Rocker\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Nice windscreen protects my MXL mic and preven...</td>\n",
       "      <td>5</td>\n",
       "      <td>GOOD WINDSCREEN FOR THE MONEY</td>\n",
       "      <td>1392336000</td>\n",
       "      <td>02 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A94QU4C90B1AX</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>SEAN MASLANKA</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This pop filter is great. It looks and perform...</td>\n",
       "      <td>5</td>\n",
       "      <td>No more pops when I record my vocals.</td>\n",
       "      <td>1392940800</td>\n",
       "      <td>02 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10256</td>\n",
       "      <td>A14B2YH83ZXMPP</td>\n",
       "      <td>B00JBIVXGC</td>\n",
       "      <td>Lonnie M. Adams</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Great, just as expected.  Thank to all.</td>\n",
       "      <td>5</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1405814400</td>\n",
       "      <td>07 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10257</td>\n",
       "      <td>A1RPTVW5VEOSI</td>\n",
       "      <td>B00JBIVXGC</td>\n",
       "      <td>Michael J. Edelman</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I've been thinking about trying the Nanoweb st...</td>\n",
       "      <td>5</td>\n",
       "      <td>Long life, and for some players, a good econom...</td>\n",
       "      <td>1404259200</td>\n",
       "      <td>07 2, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10258</td>\n",
       "      <td>AWCJ12KBO5VII</td>\n",
       "      <td>B00JBIVXGC</td>\n",
       "      <td>Michael L. Knapp</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I have tried coated strings in the past ( incl...</td>\n",
       "      <td>4</td>\n",
       "      <td>Good for coated.</td>\n",
       "      <td>1405987200</td>\n",
       "      <td>07 22, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10259</td>\n",
       "      <td>A2Z7S8B5U4PAKJ</td>\n",
       "      <td>B00JBIVXGC</td>\n",
       "      <td>Rick Langdon \"Scriptor\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Well, MADE by Elixir and DEVELOPED with Taylor...</td>\n",
       "      <td>4</td>\n",
       "      <td>Taylor Made</td>\n",
       "      <td>1404172800</td>\n",
       "      <td>07 1, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10260</td>\n",
       "      <td>A2WA8TDCTGUADI</td>\n",
       "      <td>B00JBIVXGC</td>\n",
       "      <td>TheTerrorBeyond</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These strings are really quite good, but I wou...</td>\n",
       "      <td>4</td>\n",
       "      <td>These strings are really quite good, but I wou...</td>\n",
       "      <td>1405468800</td>\n",
       "      <td>07 16, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10261 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviewerID        asin  \\\n",
       "0      A2IBPI20UZIR0U  1384719342   \n",
       "1      A14VAT5EAX3D9S  1384719342   \n",
       "2      A195EZSQDW3E21  1384719342   \n",
       "3      A2C00NNG1ZQQG2  1384719342   \n",
       "4       A94QU4C90B1AX  1384719342   \n",
       "...               ...         ...   \n",
       "10256  A14B2YH83ZXMPP  B00JBIVXGC   \n",
       "10257   A1RPTVW5VEOSI  B00JBIVXGC   \n",
       "10258   AWCJ12KBO5VII  B00JBIVXGC   \n",
       "10259  A2Z7S8B5U4PAKJ  B00JBIVXGC   \n",
       "10260  A2WA8TDCTGUADI  B00JBIVXGC   \n",
       "\n",
       "                                           reviewerName   helpful  \\\n",
       "0      cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                                  Jake  [13, 14]   \n",
       "2                         Rick Bennette \"Rick Bennette\"    [1, 1]   \n",
       "3                             RustyBill \"Sunday Rocker\"    [0, 0]   \n",
       "4                                         SEAN MASLANKA    [0, 0]   \n",
       "...                                                 ...       ...   \n",
       "10256                                   Lonnie M. Adams    [0, 0]   \n",
       "10257                                Michael J. Edelman    [0, 0]   \n",
       "10258                                  Michael L. Knapp    [0, 0]   \n",
       "10259                           Rick Langdon \"Scriptor\"    [0, 0]   \n",
       "10260                                   TheTerrorBeyond    [0, 0]   \n",
       "\n",
       "                                              reviewText  overall  \\\n",
       "0      Not much to write about here, but it does exac...        5   \n",
       "1      The product does exactly as it should and is q...        5   \n",
       "2      The primary job of this device is to block the...        5   \n",
       "3      Nice windscreen protects my MXL mic and preven...        5   \n",
       "4      This pop filter is great. It looks and perform...        5   \n",
       "...                                                  ...      ...   \n",
       "10256            Great, just as expected.  Thank to all.        5   \n",
       "10257  I've been thinking about trying the Nanoweb st...        5   \n",
       "10258  I have tried coated strings in the past ( incl...        4   \n",
       "10259  Well, MADE by Elixir and DEVELOPED with Taylor...        4   \n",
       "10260  These strings are really quite good, but I wou...        4   \n",
       "\n",
       "                                                 summary  unixReviewTime  \\\n",
       "0                                                   good      1393545600   \n",
       "1                                                   Jake      1363392000   \n",
       "2                                   It Does The Job Well      1377648000   \n",
       "3                          GOOD WINDSCREEN FOR THE MONEY      1392336000   \n",
       "4                  No more pops when I record my vocals.      1392940800   \n",
       "...                                                  ...             ...   \n",
       "10256                                         Five Stars      1405814400   \n",
       "10257  Long life, and for some players, a good econom...      1404259200   \n",
       "10258                                   Good for coated.      1405987200   \n",
       "10259                                        Taylor Made      1404172800   \n",
       "10260  These strings are really quite good, but I wou...      1405468800   \n",
       "\n",
       "        reviewTime  \n",
       "0      02 28, 2014  \n",
       "1      03 16, 2013  \n",
       "2      08 28, 2013  \n",
       "3      02 14, 2014  \n",
       "4      02 21, 2014  \n",
       "...            ...  \n",
       "10256  07 20, 2014  \n",
       "10257   07 2, 2014  \n",
       "10258  07 22, 2014  \n",
       "10259   07 1, 2014  \n",
       "10260  07 16, 2014  \n",
       "\n",
       "[10261 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If the spacy model isnt downloaded yet, do that first\n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "# Load the model\n",
    "spac = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the entities in the text\n",
    "def get_entities(spacy_txt):\n",
    "    # spacy_txt: spacy object produced by parsing the txt file\n",
    "    print(spacy_txt)\n",
    "    for ent in spacy_txt.ents:\n",
    "        # format of entities inside the object\n",
    "        # documentation: https://spacy.io/usage/linguistic-features#named-entities\n",
    "        print(ent.text, \"\\n\", ent.start_char, \"\\t\", ent.end_char, \"\\t\", ent.label_)\n",
    "        print(\"__\"* 50)\n",
    "    return None\n",
    "\n",
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"load stop words \"\"\"\n",
    "    \n",
    "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)\n",
    "        \n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# load a set of stop words\n",
    "stopwords=get_stop_words(\"Data/stopwords.txt\")\n",
    "\n",
    "# preprocess the reviewText\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x:pre_process(x))\n",
    "\n",
    "#get the text column \n",
    "docs=data['reviewText'].tolist()\n",
    "\n",
    "#create a vocabulary of words, \n",
    "#ignore words that appear in 85% of documents, \n",
    "#eliminate stop words\n",
    "cv = CountVectorizer(max_df = 0.85, stop_words = stopwords, max_features=10000)\n",
    "word_count_vector = cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer(smooth_idf = True, use_idf = True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(text):\n",
    "\n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector = tfidf_transformer.transform(cv.transform([text]))\n",
    "\n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items = sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "    #extract only the top n; n here is 10\n",
    "    keywords = extract_topn_from_vector(feature_names, sorted_items, 10)\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def print_results(text, keywords):\n",
    "    # now print the results\n",
    "    print(\"\\n=====Review=====\")\n",
    "    print(text)\n",
    "    print(\"\\n===Keywords===\")\n",
    "    for k in keywords:\n",
    "        print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you only needs to do this once\n",
    "feature_names=cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = []\n",
    "\n",
    "# Print results and create new dataset\n",
    "for index, row in data.iterrows():\n",
    "    text = row['reviewText']\n",
    "    keywords = get_keywords(text)\n",
    "    keyword_list.append(list(keywords.keys()))\n",
    "    # print_results(text, keywords)\n",
    "    \n",
    "data['keywords'] = keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json('Data/processed_reviews.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
